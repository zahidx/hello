{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zahidx/hello/blob/main/Copy_of_Lab_Assignment_03_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWxyXBa8znbt"
      },
      "source": [
        "#### **Wheat Seed Classification**\n",
        "\n",
        "In this assignment, you will use the [Wheat Seed Dataset](https://archive.ics.uci.edu/ml/datasets/seeds) to classify the type of wheat seed based on the measurements of the seed. The dataset contains 7 attributes and 210 instances. The attributes are:\n",
        "\n",
        "1. Area\n",
        "2. Perimeter\n",
        "3. Compactness\n",
        "4. Length of Kernel\n",
        "5. Width of Kernel\n",
        "6. Asymmetry Coefficient\n",
        "7. Length of Kernel Groove\n",
        "\n",
        "Based on the attributes, the dataset contains 3 classes:\n",
        "\n",
        "1. Kama\n",
        "2. Rosa\n",
        "3. Canadian\n",
        "\n",
        "The text file `seeds_dataset.txt` contains the dataset. The first 7 columns are the attributes and the last column is the class label. The class labels are encoded as  1, 2, and 3 for Kama, Rosa, and Canadian, respectively. The goal of this assignment is to build a classifier that can predict the type of wheat seed based on the measurements of the seed. Follow the instructions below to complete the assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAq8IStpznbu"
      },
      "source": [
        "#### **Step 1:** Download the dataset from [here](https://drive.google.com/file/d/1ZnGOVGFrNv0L1ctT8SO8Y3WfjD2HShgK/view?usp=sharing). It should be saved as `seeds_dataset.csv`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 2:** Upload the dataset to your Google Drive and mount your Google Drive to Colab.\n"
      ],
      "metadata": {
        "id": "mMMaH9XZq6Nr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJ-JGvLg8f1F",
        "outputId": "7dfcbe8a-a03e-4796-fc02-a3bb4992ae1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('/content/sample_data/seeds_dataset.csv')\n",
        "data.head()\n"
      ],
      "metadata": {
        "id": "wrj5rEhkqsmX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "90fbab46-09c5-4b35-e09e-d26d0ef8f328"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   15.26\\t14.84\\t0.871\\t5.763\\t3.312\\t2.221\\t5.22\\t1\n",
              "0  14.88\\t14.57\\t0.8811\\t5.554\\t3.333\\t1.018\\t4.9...\n",
              "1  14.29\\t14.09\\t0.905\\t5.291\\t3.337\\t2.699\\t4.82...\n",
              "2  13.84\\t13.94\\t0.8955\\t5.324\\t3.379\\t2.259\\t4.8...\n",
              "3  16.14\\t14.99\\t0.9034\\t5.658\\t3.562\\t1.355\\t5.1...\n",
              "4  14.38\\t14.21\\t0.8951\\t5.386\\t3.312\\t2.462\\t4.9..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-774c084c-fda2-42d5-a359-5f47570077ea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>15.26\\t14.84\\t0.871\\t5.763\\t3.312\\t2.221\\t5.22\\t1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.88\\t14.57\\t0.8811\\t5.554\\t3.333\\t1.018\\t4.9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14.29\\t14.09\\t0.905\\t5.291\\t3.337\\t2.699\\t4.82...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.84\\t13.94\\t0.8955\\t5.324\\t3.379\\t2.259\\t4.8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16.14\\t14.99\\t0.9034\\t5.658\\t3.562\\t1.355\\t5.1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14.38\\t14.21\\t0.8951\\t5.386\\t3.312\\t2.462\\t4.9...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-774c084c-fda2-42d5-a359-5f47570077ea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-774c084c-fda2-42d5-a359-5f47570077ea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-774c084c-fda2-42d5-a359-5f47570077ea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 3:** Read the dataset using pandas' built-in function `pd.read_csv()` as `data` convert it into numpy array using `data.to_numpy()` function. Pass the following parameters to the `pd.read_csv()`function:\n",
        "    \n",
        "\n",
        "*   `filepath_or_buffer`: The path to the dataset\n",
        "*   `delimiter`: The delimiter used in the dataset to separate the attributes (Hint: Use `'\\t'` as the delimiter)\n",
        "*   `header`: The column header used in the dataset (Hint: Use `None` as the header)\n"
      ],
      "metadata": {
        "id": "QzgDpOJ_q2FO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your code here\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Step 3: Read the dataset using pandas\n",
        "filepath_or_buffer = \"/content/sample_data/seeds_dataset.csv\"  # Replace with the actual path to your dataset\n",
        "delimiter = \"\\t\"  # Specify the delimiter used in your dataset\n",
        "header = None  # Specify None as the header\n",
        "\n",
        "data = pd.read_csv(filepath_or_buffer, delimiter=delimiter, header=header)\n",
        "data_array = data.to_numpy()\n",
        "\n",
        "print(\"Data Array:\")\n",
        "print(data_array)\n",
        "\n"
      ],
      "metadata": {
        "id": "e3P-LnslbOzU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf0511b6-9336-455a-b5d7-cd8e99e14313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Array:\n",
            "[[15.26   14.84    0.871  ...  2.221   5.22    1.    ]\n",
            " [14.88   14.57    0.8811 ...  1.018   4.956   1.    ]\n",
            " [14.29   14.09    0.905  ...  2.699   4.825   1.    ]\n",
            " ...\n",
            " [13.2    13.66    0.8883 ...  8.315   5.056   3.    ]\n",
            " [11.84   13.21    0.8521 ...  3.598   5.044   3.    ]\n",
            " [12.3    13.34    0.8684 ...  5.637   5.063   3.    ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **Step 4:** Shuffle the dataset using `np.random.shuffle()`. Pass the following parameters to the function:\n",
        "* `x`: The dataset\n"
      ],
      "metadata": {
        "id": "vNyVHevnrleZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your code here\n",
        "import numpy as np\n",
        "\n",
        "# Assuming the dataset is stored in a numpy array called 'data_array'\n",
        "# Shuffle the dataset using np.random.shuffle()\n",
        "np.random.shuffle(data_array)\n",
        "\n",
        "# Print the shuffled dataset\n",
        "print(\"Shuffled Data Array:\")\n",
        "print(data_array)\n"
      ],
      "metadata": {
        "id": "cY7keX9Xrw3M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fe78671-346c-4020-ef46-741018de84d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shuffled Data Array:\n",
            "[[18.36   16.52    0.8452 ...  4.933   6.448   2.    ]\n",
            " [16.84   15.67    0.8623 ...  4.675   5.877   2.    ]\n",
            " [15.05   14.68    0.8779 ...  2.129   5.36    1.    ]\n",
            " ...\n",
            " [12.26   13.6     0.8333 ...  4.756   5.36    3.    ]\n",
            " [13.5    13.85    0.8852 ...  2.249   5.176   1.    ]\n",
            " [12.88   13.5     0.8879 ...  2.352   4.607   1.    ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 5:**  Split the dataset into features and labels. The first 7 columns of the dataset are the features and the last column is the label. Use numpy's array slicing to split the dataset into features and labels. (Hint: Use `:` to select all the rows and `0:7` to select the first 7 columns for features and `7` to select the last column for labels)\n"
      ],
      "metadata": {
        "id": "Zec6rLbDryO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your code here\n",
        "import numpy as np\n",
        "\n",
        "# Assuming the dataset is stored in a numpy array called 'data_array'\n",
        "# Split the dataset into features and labels\n",
        "features = data_array[:, 0:7]  # Select all rows and first 7 columns for features\n",
        "labels = data_array[:, 7]  # Select all rows and last column for labels\n",
        "\n",
        "# Print the features and labels\n",
        "print(\"Features:\")\n",
        "print(features)\n",
        "print(\"Labels:\")\n",
        "print(labels)\n"
      ],
      "metadata": {
        "id": "brUfzEJBr7Lm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bb42b3f-c362-4941-eb0d-a025a770e0a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features:\n",
            "[[18.36   16.52    0.8452 ...  3.485   4.933   6.448 ]\n",
            " [16.84   15.67    0.8623 ...  3.484   4.675   5.877 ]\n",
            " [15.05   14.68    0.8779 ...  3.328   2.129   5.36  ]\n",
            " ...\n",
            " [12.26   13.6     0.8333 ...  2.833   4.756   5.36  ]\n",
            " [13.5    13.85    0.8852 ...  3.158   2.249   5.176 ]\n",
            " [12.88   13.5     0.8879 ...  3.119   2.352   4.607 ]]\n",
            "Labels:\n",
            "[2. 2. 1. 1. 3. 1. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2. 3. 3. 2. 3. 2. 1. 3. 3.\n",
            " 2. 1. 1. 3. 1. 2. 3. 1. 1. 3. 3. 2. 3. 1. 1. 1. 1. 3. 2. 3. 1. 3. 2. 2.\n",
            " 1. 3. 1. 3. 1. 2. 2. 1. 1. 2. 2. 1. 3. 3. 2. 2. 3. 1. 1. 3. 1. 2. 3. 2.\n",
            " 2. 2. 1. 3. 2. 1. 3. 2. 3. 2. 3. 1. 1. 2. 2. 2. 3. 2. 1. 3. 2. 1. 3. 1.\n",
            " 2. 3. 3. 3. 3. 2. 1. 3. 1. 3. 2. 3. 3. 3. 3. 1. 1. 2. 1. 3. 1. 2. 2. 3.\n",
            " 1. 3. 1. 3. 3. 1. 2. 3. 2. 1. 1. 1. 2. 3. 3. 1. 1. 3. 2. 2. 3. 3. 1. 3.\n",
            " 3. 3. 1. 3. 3. 2. 1. 2. 1. 2. 1. 2. 1. 1. 2. 2. 1. 1. 2. 3. 3. 1. 2. 1.\n",
            " 2. 1. 2. 2. 2. 2. 3. 1. 2. 2. 1. 2. 2. 3. 2. 3. 2. 3. 3. 3. 3. 1. 3. 1.\n",
            " 2. 3. 3. 2. 3. 3. 3. 1. 2. 1. 1. 2. 1. 2. 1. 3. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 6:**  Split the dataset into training and testing sets. Use numpy's built-in function `np.split()` to split the dataset into training and testing sets. Pass the following parameters to the function:\n",
        "* `ary`: The dataset\n",
        "* `indices_or_sections`: The number of instances in the training set (Hint: Use `int(0.8 * len(dataset))` to get the number of instances in the training set)\n",
        "* `axis`: The axis to split the dataset (Hint: Use `0` to split the dataset along the rows)\n"
      ],
      "metadata": {
        "id": "SUVjOZxxr9Ga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your code here\n",
        "import numpy as np\n",
        "\n",
        "# Assuming the dataset is stored in a numpy array called 'data_array'\n",
        "# Calculate the number of instances in the training set\n",
        "train_size = int(0.8 * len(data_array))\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "train_data, test_data = np.split(data_array, [train_size], axis=0)\n",
        "\n",
        "# Print the shapes of the training and testing sets\n",
        "print(\"Train Data Shape:\", train_data.shape)\n",
        "print(\"Test Data Shape:\", test_data.shape)\n"
      ],
      "metadata": {
        "id": "P6uV-duTsRkW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c28ad10-6b15-4b99-e6ae-a0fd5f914d19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data Shape: (168, 8)\n",
            "Test Data Shape: (42, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 7:**  Find the minimum and maximum values of each feature in the training set. Use numpy's built-in function `np.min()` and `np.max()` to find the minimum and maximum values of each feature in the training set. Pass the following parameters to the function:\n",
        "* `a`: The training set\n",
        "* `axis`: The axis to find the minimum and maximum values (Hint: Use `0` to find the minimum and maximum values along the columns)"
      ],
      "metadata": {
        "id": "zq0cHk5DsSTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your code here\n",
        "import numpy as np\n",
        "\n",
        "# Assuming the training set is stored in a numpy array called 'train_data'\n",
        "# Find the minimum and maximum values of each feature in the training set\n",
        "min_values = np.min(train_data, axis=0)  # Axis=0 to find along columns\n",
        "max_values = np.max(train_data, axis=0)  # Axis=0 to find along columns\n",
        "\n",
        "# Print the minimum and maximum values of each feature\n",
        "print(\"Minimum Values of Features:\")\n",
        "print(min_values)\n",
        "print(\"Maximum Values of Features:\")\n",
        "print(max_values)\n"
      ],
      "metadata": {
        "id": "xwB4BJxHscLp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "442c441f-858a-417d-c90d-e335939b3b2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum Values of Features:\n",
            "[10.59   12.41    0.8082  4.899   2.63    0.7651  4.519   1.    ]\n",
            "Maximum Values of Features:\n",
            "[21.18   17.25    0.9183  6.675   4.033   8.456   6.55    3.    ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Step 8:**  In this step, you must normalize the training and test sets. Nomalization is an essential part of every machine learning project. It is used to bring all the features to the same scale. If the features are not normalized, the higher-valued features will outnumber the lower-valued ones.\n",
        "\n",
        "For example, suppose we have a dataset with two features: the number of bedrooms in a house and the size of the garden in square feet and we are trying to forecast the rent of the residence. If the features are not normalized, the feature with higher values will take precedence over the feature with lower values. In this scenario, the garden area has a greater value. As a result, the model will make an attempt to forecast the house's price depending on the size of the garden. As a consequence, the model will be faulty since most individuals will not pay higher rent for more garden area. We need to normalize the features in order to prevent this. Let's look at the following illustration to better comprehend what we have said:\n",
        "* House 1: 2 bedrooms, 2500 sq. ft. garden\n",
        "* House 2: 3 bedrooms, 500 sq. ft. garden\n",
        "* House 3: 7 bedrooms, 2300 sq. ft. garden\n",
        "\n",
        "Considering that most people won't pay more for a larger garden, it follows that the rent for House 1 should be more comparable to House 2 than to House 3. However, if we give the aforementioned data to a k-NN classifier without normalization, it will compute the euclidean distance between the test and training examples and pick the class of the test instance based on the class of the closest training instance.\n",
        "\n",
        "The euclidean distance between the test instance and the training instances will be:\n",
        "\n",
        "* Distance between house 1 and house 2: $\\sqrt{(2-3)^2 + (2500-500)^2} = 2000$\n",
        "* Distance between house 1 and house 3: $\\sqrt{(2-7)^2 + (2500-2300)^2} = 200$\n",
        "\n",
        "As you can see, the distance between houses 1 and 3 is shorter than that between houses 1 and 2. As a result, the model will forecast that house 1 will cost around the same as house 3. This is not what was anticipated. We need to normalize the features in order to prevent this. To normalize the features, subtract the minimum value of each feature from all the values of that feature and divide the result by the range of the feature. The range of a feature is the difference between the maximum and minimum values of that feature. The formula for normalization is given below:\n",
        "\n",
        "$$x_{normalized} = \\frac{x - min(x)}{max(x) - min(x)}$$\n",
        "\n",
        "<html>\n",
        "<center> \n",
        "where, $x$ is the feature vector. The above formula will normalize the features to a scale of 0 to 1.\n",
        "</center>\n",
        "</html>\n",
        "\n",
        "\n",
        "\n",
        "Let's normalize the features in the above example. To do so, we need to find the minimum and maximum values of each feature. The minimum and maximum values of the number of bedrooms are 2 and 7, respectively. The minimum and maximum values of the garden area are 500 and 2500, respectively. The normalized values of the features are given below:\n",
        "\n",
        "* House 1: $(2 - 2) / 5 = 0$ bedrooms, $(2500 - 500) / 2000 = 0.75$ sq. ft. garden\n",
        "* House 2: $(3 - 2) / 5 = 0.2$ bedrooms, $(500 - 500) / 2000 = 0$ sq. ft. garden\n",
        "* House 3: $(7 - 2) / 5 = 1$ bedrooms, $(2300 - 500) / 2000 = 0.85$ sq. ft. garden\n",
        "\n",
        "Now, the euclidean distance between the test instance and the training instances will be:\n",
        "\n",
        "* Distance between house 1 and house 2: $\\sqrt{(0-0.2)^2 + (0.75-0)^2} = 0.77$\n",
        "* Distance between house 1 and house 3: $\\sqrt{(0-1)^2 + (0.75-0.9)^2} = 1.11$\n",
        "\n",
        "As you can see now, the distance between houses 1 and 2 is shorter than that between houses 1 and 3. The model will thus forecast that house 1 will cost about the same as house 2, according to the prediction. This is what is anticipated. This is what normalization does. It equalizes the scale of all features. This is important because it prevents the features with higher values from dominating the features with lower values.\n",
        "\n",
        "Use the minimum and maximum values you found in the previous step to normalize the training and test sets.\n"
      ],
      "metadata": {
        "id": "KTdEBT_Jsc9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load the dataset from a text file\n",
        "data = np.loadcsv('/content/sample_data/seeds_dataset.csv')\n",
        "\n",
        "# Extract the features (first 7 columns) and labels (last column)\n",
        "X = data[:, :-1]\n",
        "y = data[:, -1]\n",
        "\n",
        "# Define a function to normalize the features\n",
        "def normalize_features(X):\n",
        "    \"\"\"\n",
        "    Normalizes the features of a dataset to a scale of 0 to 1.\n",
        "    \n",
        "    Parameters:\n",
        "        -- X: numpy array, shape (n_samples, n_features)\n",
        "            The input dataset.\n",
        "            \n",
        "    Returns:\n",
        "        -- X_norm: numpy array, shape (n_samples, n_features)\n",
        "            The normalized dataset.\n",
        "    \"\"\"\n",
        "    # Compute the minimum and maximum values for each feature\n",
        "    min_vals = np.min(X, axis=0)\n",
        "    max_vals = np.max(X, axis=0)\n",
        "    \n",
        "    # Normalize the features using the formula x_normalized = (x - min) / (max - min)\n",
        "    X_norm = (X - min_vals) / (max_vals - min_vals)\n",
        "    \n",
        "    return X_norm\n",
        "\n",
        "# Normalize the features of the dataset\n",
        "X_norm = normalize_features(X)\n",
        "\n",
        "# Print the normalized features\n",
        "print(\"Normalized Features:\")\n",
        "print(X_norm)\n"
      ],
      "metadata": {
        "id": "d8NmhrprtWy1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "4c282f01-5d39-42dd-eb9d-6b886c041c3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-980e745b0d3b>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the dataset from a text file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/sample_data/seeds_dataset.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Extract the features (first 7 columns) and labels (last column)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mTester\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         raise AttributeError(\"module {!r} has no attribute \"\n\u001b[0m\u001b[1;32m    316\u001b[0m                              \"{!r}\".format(__name__, attr))\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'loadcsv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Step 9:**  Now, you have to build a classifier to classify the type of wheat seed based on the measurements of the seed. Use the K-Nearest Neighbors algorithm to build the classifier. Use the Euclidean distance to find the nearest neighbors.\n"
      ],
      "metadata": {
        "id": "3y_RpB0YtXxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your code here\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load your preprocessed data\n",
        "X = train_set_normalized  # Features\n",
        "y = labels  # Labels\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the KNN classifier with k=3 (you can change k as desired)\n",
        "k = 3\n",
        "knn = KNeighborsClassifier(n_neighbors=k)\n",
        "\n",
        "# Train the KNN classifier on the training set\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Calculate accuracy of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "sqvuOZ9Utdpl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "145b60cc-8e71-473c-922b-e5390dac18a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-fbfd6d2b59cb>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Load your preprocessed data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_set_normalized\u001b[0m  \u001b[0;31m# Features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m  \u001b[0;31m# Labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_set_normalized' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Step 10:**  Output the number of data points in the testing set and the number of correct predictions made by the classifier for each class."
      ],
      "metadata": {
        "id": "cCXjvR3AteaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your code here\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load your preprocessed data\n",
        "X = train_set_normalized  # Features\n",
        "y = labels  # Labels\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the KNN classifier with k=3 (you can change k as desired)\n",
        "k = 3\n",
        "knn = KNeighborsClassifier(n_neighbors=k)\n",
        "\n",
        "# Train the KNN classifier on the training set\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Calculate accuracy of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Output number of data points in the testing set\n",
        "num_test_data_points = len(y_test)\n",
        "print(\"Number of data points in the testing set:\", num_test_data_points)\n",
        "\n",
        "# Output number of correct predictions for each class\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Number of correct predictions for each class:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "CLR_LFwvti0V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "281fef5e-3826-409f-bd23-a5e0f8410b6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-1ba4fa3b1104>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Load your preprocessed data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_set_normalized\u001b[0m  \u001b[0;31m# Features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m  \u001b[0;31m# Labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_set_normalized' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "b148fc9bfa8b60132af830e32e1690e4e023b803e92912df15b823b90141dda6"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}